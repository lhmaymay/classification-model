import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
df_train=pd.read_csv('C:/Users/uicma/OneDrive/Desktop/paypal/interview_data_train.csv')
df_test=pd.read_csv('C:/Users/uicma/OneDrive/Desktop/paypal/interview_data_test.csv')
df_train.info()
df_train.isnull().sum()
df_test.isnull().sum()
df_train.describe()
df_test.describe()

# feature selection: check correlations
df_train.corr().to_csv('C:/Users/uicma/OneDrive/Desktop/paypal/interview_data_train_corr.csv')

df_train.y.value_counts()
df_test.y.value_counts()
x_train=df_train.drop(['y'],axis=1)
corr = x_train.corr()
x_test=df_test.drop(['y'],axis=1)
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.grid_search import GridSearchCV   #Perforing grid search
from xgboost import plot_importance
from sklearn.model_selection import cross_val_score,KFold,train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score,f1_score, precision_score, recall_score, classification_report, confusion_matrix
X=df_train.drop(['y'],axis=1)

# Principle component analysis
from sklearn.decomposition import PCA
pca = PCA(n_components=50)
pca.fit(x_train)
X_pca = pca.transform(X)
print("original shape:   ", X.shape)
print("transformed shape:", X_pca.shape)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');

pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['principal component 1', 'principal component 2'])

# check VIF variance inflation factor
from statsmodels.stats.outliers_influence import variance_inflation_factor    
def calculate_vif_(X, thresh=5.0):
    variables = list(range(X.shape[1]))
    dropped = True
    while dropped:
        dropped = False
        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)
               for ix in range(X.iloc[:, variables].shape[1])]
        maxloc = vif.index(max(vif))
        if max(vif) > thresh:
            print('dropping \'' + X.iloc[:, variables].columns[maxloc] +
                  '\' at index: ' + str(maxloc))
            del variables[maxloc]
            dropped = True
    print('Remaining variables:')
    print(X.columns[variables])
    return X.iloc[:, variables]

calculate_vif_(x_train,thresh=5.0)
# only keep those with lower VIF<5

x_train3.corr().to_csv('train3.csv')
x_train3=df_train[['x3', 'x4', 'x5', 'x6', 'x19', 'x36', 'x38', 'x39', 'x40', 'x41', 'x45',
       'x52', 'x69', 'x91', 'x92', 'x93', 'x94', 'x96']]
x_test3=df_test[['x3', 'x4', 'x5', 'x6', 'x19', 'x36', 'x38', 'x39', 'x40', 'x41', 'x45',
       'x52', 'x69', 'x91', 'x92', 'x93', 'x94', 'x96']]
columns = np.full((corr.shape[0],), True, dtype=bool)

# check variable (candidate predictor) correlation, only keep one if corr>=0.9
for i in range(corr.shape[0]):
    for j in range(i+1, corr.shape[0]):
        if corr.iloc[i,j] >= 0.9:
            if columns[j]:
                columns[j] = False
selected_columns = x_train.columns[columns]
x_train2=x_train[selected_columns]
corr = x_test.corr()
columns = np.full((corr.shape[0],), True, dtype=bool)
for i in range(corr.shape[0]):
    for j in range(i+1, corr.shape[0]):
        if corr.iloc[i,j] >= 0.9:
            if columns[j]:
                columns[j] = False
selected_columns = x_test.columns[columns]
x_test2=x_test[selected_columns]
x_test2.info()

# compare different classification algorithms
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
# load dataset
X = x_train3
Y = df_train.y
# prepare configuration for cross validation test harness
seed = 7
# prepare models
models = []
models.append(('LR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))
models.append(('XGBoost', XGBClassifier()))
# evaluate each model in turn
results = []
names = []
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed)
	cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)
# boxplot algorithm comparison
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()
algos = ["Support Vector Machine","Decision Tree","Logistic Regression","K Nearest Neighbor","Naive Bayes","XGBoost","LDA"]
clfs = [SVC(kernel="linear"),DecisionTreeClassifier(),LogisticRegression(),KNeighborsClassifier(n_neighbors=2),GaussianNB(),
       XGBClassifier(n_estimators=100,learning_rate=0.1,gamma=0,subsample=0.6,reg_alpha=0.75,reg_lambda=0.5,min_child_weight=50,colsample_bytree=0.7,
                     max_depth=5,seed=500),LinearDiscriminantAnalysis()]

# K-fold cross-validation results comparison
cv_results=[]
for classifiers in clfs:
    cv_score = cross_val_score(classifiers,X,Y,cv=kfold,scoring="accuracy")
    cv_results.append(cv_score.mean())
cv_mean = pd.DataFrame(cv_results,index=algos)
cv_mean.columns=["Accuracy"]
cv_mean.sort_values(by="Accuracy",ascending=False)

# partital dependence plot
from sklearn.ensemble.partial_dependence import plot_partial_dependence
from sklearn.ensemble.partial_dependence import partial_dependence
from sklearn.ensemble import GradientBoostingClassifier
model=GradientBoostingClassifier(n_estimators=100,max_depth=5,learning_rate=0.1,random_state=50)
model.fit(x_train3,df_train.y)
fig,axs=plot_partial_dependence(model,x_train3,[16],n_jobs=7,grid_resolution=50)
plt.subplots_adjust(top=0.9)
fig,axs=plot_partial_dependence(model,x_train3,[0],n_jobs=7,grid_resolution=50)
plt.subplots_adjust(top=0.9)
clf.fit(x_train3,df_train.y)

# print feature importance plot, and cumulative feature importance
print(clf.feature_importances_)
(pd.Series(clf.feature_importances_,index=x_train3.columns).nlargest(20).plot(kind='bar'))
print(roc_auc_score(df_train.y,clf.predict(x_train3)),accuracy_score(df_train.y,clf.predict(x_train3)))

clf.fit(x_test3,df_test.y)
print(clf.feature_importances_)
(pd.Series(clf.feature_importances_,index=x_test3.columns).nlargest(20).plot(kind='bar'))
feature_importances = pd.DataFrame(clf.feature_importances_,
                                   index = x_train3.columns,
                                    columns=['importance']).sort_values('importance',ascending=False)
print(feature_importances)
print(roc_auc_score(df_test.y,clf.predict(x_test3)),accuracy_score(df_test.y,clf.predict(x_test3)))
